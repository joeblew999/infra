# Fly.io configuration for core-caddy (Edge Proxy)
# Phase 2: Microservices deployment
# Service: Public-facing reverse proxy with TLS termination

app = 'core-caddy'
primary_region = 'syd'
kill_signal = 'SIGTERM'
kill_timeout = '15s'

[build]
  # Single binary deployment - run specific subcommand

[env]
  # Upstream service URLs (private network)
  POCKETBASE_URL = 'http://core-pocketbase.internal:8090'
  NATS_URL = 'http://core-nats.internal:8222'

  # Observability
  NATS_EVENTS_URL = 'nats://core-nats.internal:4222'
  OBSERVABILITY_ENABLED = 'true'
  SERVICE_NAME = 'core-caddy'

  # Production mode
  ENVIRONMENT = 'production'

# No persistent storage needed (stateless proxy)

# HTTP/HTTPS service (public-facing)
[[services]]
  protocol = 'tcp'
  internal_port = 2015
  auto_stop_machines = 'stop'
  auto_start_machines = true
  min_machines_running = 1

  # HTTP port (redirect to HTTPS)
  [[services.ports]]
    port = 80
    handlers = ['http']

    [services.ports.http_options]
      compress = true

  # HTTPS port (TLS termination)
  [[services.ports]]
    port = 443
    handlers = ['tls', 'http']

    [services.ports.http_options]
      compress = true

  # Connection limits
  [services.concurrency]
    type = 'connections'
    hard_limit = 100
    soft_limit = 80

  # Health checks
  [[services.http_checks]]
    interval = '15s'
    timeout = '10s'
    grace_period = '20s'
    method = 'GET'
    path = '/api/health'
    protocol = 'http'

  # TCP health check as fallback
  [[services.tcp_checks]]
    interval = '15s'
    timeout = '10s'
    grace_period = '20s'

# VM resources (lightweight proxy)
[[vm]]
  memory = '256mb'
  cpu_kind = 'shared'
  cpus = 1

# Deployment configuration (rolling updates)
[deploy]
  strategy = 'rolling'
  max_unavailable = 0  # Zero-downtime for edge proxy

# Auto-scaling configuration
[http_service]
  internal_port = 2015
  force_https = true
  auto_stop_machines = 'stop'
  auto_start_machines = true
  min_machines_running = 1
  max_machines_running = 3  # Scale up to 3 instances

  [http_service.concurrency]
    type = 'connections'
    hard_limit = 100
    soft_limit = 80
